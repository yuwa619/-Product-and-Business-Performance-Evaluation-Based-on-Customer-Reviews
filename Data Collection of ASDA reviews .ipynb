{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50d160d",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS OF ASDA REVIEWS ON TRUSTPILOT - DATA COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f8b1e",
   "metadata": {},
   "source": [
    "The goal of this notebook is to perform data collection of ASDA review on Trustpilot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59005b5f",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8760a62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.26.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.26.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cufflinks as cf\n",
    "from plotly.offline import init_notebook_mode, iplot \n",
    "init_notebook_mode(connected =True)\n",
    "cf.go_offline();\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136074fb",
   "metadata": {},
   "source": [
    "## DATA COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524a14a",
   "metadata": {},
   "source": [
    "Data was collected by web scraping ASDA review page on Trustpilot using beautiful soup. The HTML was inspected and and various elements holding the data i wanted was idetified. This was then saved to a csv file and also dataframed. VPN was also used for changing IP address so when IP got to limit another was used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91efce",
   "metadata": {},
   "source": [
    "## Scraping the HTML from TrustPilot for ASDA reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b4b6256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "881b9d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve page 287. Status Code: 403\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize empty lists to store review data\n",
    "allUsers = []\n",
    "allRatings = []\n",
    "allLocations = []\n",
    "allDates = []\n",
    "allExpDate = []\n",
    "allReviewHeading = []\n",
    "allReviewContent = []\n",
    "\n",
    "# Set the maximum number of pages to scrape. maximum number of pages as at day data was scraped\n",
    "max_pages = 674\n",
    "\n",
    "# Loop through each page\n",
    "for current_page in range(1, max_pages + 1):\n",
    "    url = f\"https://uk.trustpilot.com/review/www.asda.com?page={current_page}\"\n",
    "    result = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if result.status_code != 200:\n",
    "        print(f\"Failed to retrieve page {current_page}. Status Code: {result.status_code}\")\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
    "    reviews = soup.find_all(\"div\", class_=\"styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ\")\n",
    "\n",
    "    # Check if there are reviews on the page\n",
    "    if not reviews:\n",
    "        print(f\"No reviews found on page {current_page}. Stopping...\")\n",
    "        break\n",
    "\n",
    "#After inspecting the page i found the elements holding the different dat i wanted\n",
    "        \n",
    "    for review in reviews:\n",
    "        # Extract user name\n",
    "        user = review.find(\"span\", class_=\"typography_heading-xxs__QKBS8 typography_appearance-default__AAY17\").text\n",
    "        allUsers.append(user)\n",
    "\n",
    "        # Extract star rating\n",
    "        star_rating_div = review.find(\"img\")\n",
    "        # Find the 'img' tag\n",
    "        img_tag = review.find('img')\n",
    "        # Extract the 'alt' attribute, which contains the star rating\n",
    "        alt_text = img_tag.get('alt', '')\n",
    "        # Extracting the star rating as a number\n",
    "        star_rating = int(alt_text.split()[1]) if 'Rated' in alt_text else None\n",
    "        allRatings.append(star_rating)\n",
    "\n",
    "        # Extract location (if available)\n",
    "        location_elem = review.find(\"div\", class_=\"typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua\")\n",
    "        location = location_elem.span.string if location_elem else \"\"\n",
    "        allLocations.append(location)\n",
    "\n",
    "        # Extract review date\n",
    "        time_tag = review.find('time')\n",
    "        date_string = time_tag['datetime']\n",
    "        date = datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        allDates.append(date)\n",
    "\n",
    "        # Extract experience date\n",
    "        p_tags = review.find_all('p')\n",
    "        for p_tag in p_tags:\n",
    "            if \"Date of experience\" in p_tag.text:\n",
    "                date_string = p_tag.get_text(strip=True).split(':')[1].strip()\n",
    "                try:\n",
    "                    expDate = datetime.strptime(date_string, \"%d %B %Y\")\n",
    "                    allExpDate.append(expDate)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error parsing experience date on page {current_page}: {e}\")\n",
    "                break  # Stop searching for the experience date once found\n",
    "\n",
    "        # Extract review heading\n",
    "        review_heading_tag = review.find('h2', {\"data-service-review-title-typography\": \"true\"})\n",
    "        review_heading = review_heading_tag.text.strip()\n",
    "        allReviewHeading.append(review_heading)\n",
    "\n",
    "        # Extract review content (if available)\n",
    "        review_paragraph = review.find('p', {\"data-service-review-text-typography\": \"true\"})\n",
    "        review_content = review_paragraph.text.strip() if review_paragraph else \"\"\n",
    "        allReviewContent.append(review_content)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame({\n",
    "    \"User\": allUsers,\n",
    "    \"Rating\": allRatings,\n",
    "    \"Location\": allLocations,\n",
    "    \"Date\": allDates,\n",
    "    \"ExperienceDate\": allExpDate,\n",
    "    \"ReviewHeading\": allReviewHeading,\n",
    "    \"ReviewContent\": allReviewContent\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b1fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4236c701",
   "metadata": {},
   "source": [
    "IP addresss failed to retrive beyong page 287 so i repeat code this time starting from page 305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0b3e7b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve page 530. Status Code: 403\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store review data\n",
    "allUsers = []\n",
    "allRatings = []\n",
    "allLocations = []\n",
    "allDates = []\n",
    "allExpDate = []\n",
    "allReviewHeading = []\n",
    "allReviewContent = []\n",
    "\n",
    "\n",
    "# Set the maximum number of pages to scrape\n",
    "max_pages = 674\n",
    "\n",
    "# Loop through each page\n",
    "for current_page in range(287, max_pages + 1):\n",
    "    url = f\"https://uk.trustpilot.com/review/www.asda.com?page={current_page}\"\n",
    "    result = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if result.status_code != 200:\n",
    "        print(f\"Failed to retrieve page {current_page}. Status Code: {result.status_code}\")\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
    "    reviews = soup.find_all(\"div\", class_=\"styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ\")\n",
    "\n",
    "    # Check if there are reviews on the page\n",
    "    if not reviews:\n",
    "        print(f\"No reviews found on page {current_page}. Stopping...\")\n",
    "        break\n",
    "\n",
    "#After inspecting the page i found the elements holding the different dat i wanted\n",
    "        \n",
    "    for review in reviews:\n",
    "        # Extract user name\n",
    "        user = review.find(\"span\", class_=\"typography_heading-xxs__QKBS8 typography_appearance-default__AAY17\").text\n",
    "        allUsers.append(user)\n",
    "\n",
    "        # Extract star rating\n",
    "        star_rating_div = review.find(\"img\")\n",
    "        # Find the 'img' tag\n",
    "        img_tag = review.find('img')\n",
    "        # Extract the 'alt' attribute, which contains the star rating\n",
    "        alt_text = img_tag.get('alt', '')\n",
    "        # Extracting the star rating as a number\n",
    "        star_rating = int(alt_text.split()[1]) if 'Rated' in alt_text else None\n",
    "        allRatings.append(star_rating)\n",
    "\n",
    "        # Extract location (if available)\n",
    "        location_elem = review.find(\"div\", class_=\"typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua\")\n",
    "        location = location_elem.span.string if location_elem else \"\"\n",
    "        allLocations.append(location)\n",
    "\n",
    "        # Extract review date\n",
    "        time_tag = review.find('time')\n",
    "        date_string = time_tag['datetime']\n",
    "        date = datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        allDates.append(date)\n",
    "\n",
    "        # Extract experience date\n",
    "        p_tags = review.find_all('p')\n",
    "        for p_tag in p_tags:\n",
    "            if \"Date of experience\" in p_tag.text:\n",
    "                date_string = p_tag.get_text(strip=True).split(':')[1].strip()\n",
    "                try:\n",
    "                    expDate = datetime.strptime(date_string, \"%d %B %Y\")\n",
    "                    allExpDate.append(expDate)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error parsing experience date on page {current_page}: {e}\")\n",
    "                break  # Stop searching for the experience date once found\n",
    "\n",
    "        # Extract review heading\n",
    "        review_heading_tag = review.find('h2', {\"data-service-review-title-typography\": \"true\"})\n",
    "        review_heading = review_heading_tag.text.strip()\n",
    "        allReviewHeading.append(review_heading)\n",
    "\n",
    "        # Extract review content (if available)\n",
    "        review_paragraph = review.find('p', {\"data-service-review-text-typography\": \"true\"})\n",
    "        review_content = review_paragraph.text.strip() if review_paragraph else \"\"\n",
    "        allReviewContent.append(review_content)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df1 = pd.DataFrame({\n",
    "    \"User\": allUsers,\n",
    "    \"Rating\": allRatings,\n",
    "    \"Location\": allLocations,\n",
    "    \"Date\": allDates,\n",
    "    \"ExperienceDate\": allExpDate,\n",
    "    \"ReviewHeading\": allReviewHeading,\n",
    "    \"ReviewContent\": allReviewContent\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b9284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1de43b",
   "metadata": {},
   "source": [
    "repeat the above starting from page 530 and saving in dataframe df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "afb38515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store review data\n",
    "allUsers = []\n",
    "allRatings = []\n",
    "allLocations = []\n",
    "allDates = []\n",
    "allExpDate = []\n",
    "allReviewHeading = []\n",
    "allReviewContent = []\n",
    "\n",
    "\n",
    "# Set the maximum number of pages to scrape\n",
    "max_pages = 674\n",
    "\n",
    "# Loop through each page\n",
    "for current_page in range(530, max_pages + 1):\n",
    "    url = f\"https://uk.trustpilot.com/review/www.asda.com?page={current_page}\"\n",
    "    result = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if result.status_code != 200:\n",
    "        print(f\"Failed to retrieve page {current_page}. Status Code: {result.status_code}\")\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
    "    reviews = soup.find_all(\"div\", class_=\"styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ\")\n",
    "\n",
    "    # Check if there are reviews on the page\n",
    "    if not reviews:\n",
    "        print(f\"No reviews found on page {current_page}. Stopping...\")\n",
    "        break\n",
    "\n",
    "#After inspecting the page i found the elements holding the different dat i wanted\n",
    "        \n",
    "    for review in reviews:\n",
    "        # Extract user name\n",
    "        user = review.find(\"span\", class_=\"typography_heading-xxs__QKBS8 typography_appearance-default__AAY17\").text\n",
    "        allUsers.append(user)\n",
    "\n",
    "        # Extract star rating\n",
    "        star_rating_div = review.find(\"img\")\n",
    "        # Find the 'img' tag\n",
    "        img_tag = review.find('img')\n",
    "        # Extract the 'alt' attribute, which contains the star rating\n",
    "        alt_text = img_tag.get('alt', '')\n",
    "        # Extracting the star rating as a number\n",
    "        star_rating = int(alt_text.split()[1]) if 'Rated' in alt_text else None\n",
    "        allRatings.append(star_rating)\n",
    "\n",
    "        # Extract location (if available)\n",
    "        location_elem = review.find(\"div\", class_=\"typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua\")\n",
    "        location = location_elem.span.string if location_elem else \"\"\n",
    "        allLocations.append(location)\n",
    "\n",
    "        # Extract review date\n",
    "        time_tag = review.find('time')\n",
    "        date_string = time_tag['datetime']\n",
    "        date = datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        allDates.append(date)\n",
    "\n",
    "        # Extract experience date\n",
    "        p_tags = review.find_all('p')\n",
    "        for p_tag in p_tags:\n",
    "            if \"Date of experience\" in p_tag.text:\n",
    "                date_string = p_tag.get_text(strip=True).split(':')[1].strip()\n",
    "                try:\n",
    "                    expDate = datetime.strptime(date_string, \"%d %B %Y\")\n",
    "                    allExpDate.append(expDate)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error parsing experience date on page {current_page}: {e}\")\n",
    "                break  # Stop searching for the experience date once found\n",
    "\n",
    "        # Extract review heading\n",
    "        review_heading_tag = review.find('h2', {\"data-service-review-title-typography\": \"true\"})\n",
    "        review_heading = review_heading_tag.text.strip()\n",
    "        allReviewHeading.append(review_heading)\n",
    "\n",
    "        # Extract review content (if available)\n",
    "        review_paragraph = review.find('p', {\"data-service-review-text-typography\": \"true\"})\n",
    "        review_content = review_paragraph.text.strip() if review_paragraph else \"\"\n",
    "        allReviewContent.append(review_content)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df2 = pd.DataFrame({\n",
    "    \"User\": allUsers,\n",
    "    \"Rating\": allRatings,\n",
    "    \"Location\": allLocations,\n",
    "    \"Date\": allDates,\n",
    "    \"ExperienceDate\": allExpDate,\n",
    "    \"ReviewHeading\": allReviewHeading,\n",
    "    \"ReviewContent\": allReviewContent\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d93d5",
   "metadata": {},
   "source": [
    "No more errors. Now we have three dataframes which i will concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "53374c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8391ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the DataFrames vertically\n",
    "joined = pd.concat([df, df1, df2], ignore_index=True)\n",
    "df = joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d55f6038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>ExperienceDate</th>\n",
       "      <th>ReviewHeading</th>\n",
       "      <th>ReviewContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13465</th>\n",
       "      <td>Joyce</td>\n",
       "      <td>3.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>2009-07-09 17:06:50</td>\n",
       "      <td>2009-07-09</td>\n",
       "      <td>Slow delivery</td>\n",
       "      <td>Had to wait a week for my new garden set, slow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13466</th>\n",
       "      <td>d young</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2009-06-09 08:57:17</td>\n",
       "      <td>2009-06-09</td>\n",
       "      <td>problems with them in the past 6 months</td>\n",
       "      <td>i am doing an assignment at college as part of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13467</th>\n",
       "      <td>B L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2009-05-20 16:29:05</td>\n",
       "      <td>2009-05-20</td>\n",
       "      <td>Two orders, Zero received</td>\n",
       "      <td>Ordered a game a while ago which would be disp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13468</th>\n",
       "      <td>Zena Gledhill</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IR</td>\n",
       "      <td>2009-03-07 16:25:25</td>\n",
       "      <td>2009-03-07</td>\n",
       "      <td>Ethical or not</td>\n",
       "      <td>Do you think it is ethical of asda to use a tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13469</th>\n",
       "      <td>Cilla</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2009-01-15 13:41:54</td>\n",
       "      <td>2009-01-15</td>\n",
       "      <td>Non delivery of CD</td>\n",
       "      <td>Ordered a cd on the 17th Dec 2008 still had no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                User  Rating Location                Date ExperienceDate   \n",
       "13465          Joyce     3.0       IN 2009-07-09 17:06:50     2009-07-09  \\\n",
       "13466        d young     1.0       GB 2009-06-09 08:57:17     2009-06-09   \n",
       "13467            B L     1.0       GB 2009-05-20 16:29:05     2009-05-20   \n",
       "13468  Zena Gledhill     1.0       IR 2009-03-07 16:25:25     2009-03-07   \n",
       "13469          Cilla     2.0       GB 2009-01-15 13:41:54     2009-01-15   \n",
       "\n",
       "                                 ReviewHeading   \n",
       "13465                            Slow delivery  \\\n",
       "13466  problems with them in the past 6 months   \n",
       "13467                Two orders, Zero received   \n",
       "13468                           Ethical or not   \n",
       "13469                       Non delivery of CD   \n",
       "\n",
       "                                           ReviewContent  \n",
       "13465  Had to wait a week for my new garden set, slow...  \n",
       "13466  i am doing an assignment at college as part of...  \n",
       "13467  Ordered a game a while ago which would be disp...  \n",
       "13468  Do you think it is ethical of asda to use a tr...  \n",
       "13469  Ordered a cd on the 17th Dec 2008 still had no...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a4bda42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"Date\" column to datetime\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"ExperienceDate\"] = pd.to_datetime(df[\"ExperienceDate\"])\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df.to_csv(\"trustpilot_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d35f2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter reviews from 2017 to September 2023\n",
    "start_date = datetime(2017, 1, 1)\n",
    "end_date = datetime(2023, 9, 30)\n",
    "filtered_df = df[(df[\"ExperienceDate\"] >= start_date) & (df[\"ExperienceDate\"] <= end_date)]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "filtered_df.to_csv(\"filtered_trustpilot_reviews.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aedfbf7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10790 entries, 16 to 11009\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   User            10790 non-null  object        \n",
      " 1   Rating          8546 non-null   float64       \n",
      " 2   Location        10790 non-null  object        \n",
      " 3   Date            10790 non-null  datetime64[ns]\n",
      " 4   ExperienceDate  10790 non-null  datetime64[ns]\n",
      " 5   ReviewHeading   10790 non-null  object        \n",
      " 6   ReviewContent   10790 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), object(4)\n",
      "memory usage: 674.4+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f4f0c",
   "metadata": {},
   "source": [
    "Confirming the end date for the period of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9c732ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>ExperienceDate</th>\n",
       "      <th>ReviewHeading</th>\n",
       "      <th>ReviewContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nichola</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2023-10-24 05:22:49</td>\n",
       "      <td>2023-09-15</td>\n",
       "      <td>I went in the large Asda Worksop S80 todo…</td>\n",
       "      <td>I went in the Asda Worksop S80 3NE todo my wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Robert B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2023-10-22 10:45:01</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>Never work for asda</td>\n",
       "      <td>Don't ever work for asda ....Wanted to work fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2023-10-25 10:29:52</td>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>ASDA - not refunding and not communicating.</td>\n",
       "      <td>Ordered online £72.00 of items.ASDA amended th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Uno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB</td>\n",
       "      <td>2023-10-22 07:18:18</td>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>RUBBISH</td>\n",
       "      <td>RUBBISH , I had so many orders and every time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Iain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2023-10-11 01:03:43</td>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Asda Irvine rude staff member behind…</td>\n",
       "      <td>Asda Irvine rude staff member behind counter t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User  Rating Location                Date ExperienceDate   \n",
       "16   Nichola     1.0       GB 2023-10-24 05:22:49     2023-09-15  \\\n",
       "21  Robert B     1.0       GB 2023-10-22 10:45:01     2023-09-01   \n",
       "22       Tom     1.0       GB 2023-10-25 10:29:52     2023-09-27   \n",
       "47       Uno     NaN       GB 2023-10-22 07:18:18     2023-07-15   \n",
       "99      Iain     1.0       GB 2023-10-11 01:03:43     2023-06-12   \n",
       "\n",
       "                                  ReviewHeading   \n",
       "16   I went in the large Asda Worksop S80 todo…  \\\n",
       "21                          Never work for asda   \n",
       "22  ASDA - not refunding and not communicating.   \n",
       "47                                      RUBBISH   \n",
       "99        Asda Irvine rude staff member behind…   \n",
       "\n",
       "                                        ReviewContent  \n",
       "16  I went in the Asda Worksop S80 3NE todo my wee...  \n",
       "21  Don't ever work for asda ....Wanted to work fo...  \n",
       "22  Ordered online £72.00 of items.ASDA amended th...  \n",
       "47  RUBBISH , I had so many orders and every time ...  \n",
       "99  Asda Irvine rude staff member behind counter t...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the later dates\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2fc9e23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>ExperienceDate</th>\n",
       "      <th>ReviewHeading</th>\n",
       "      <th>ReviewContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11005</th>\n",
       "      <td>Julie Driver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB</td>\n",
       "      <td>2017-01-05 18:59:56.000</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>waste of money</td>\n",
       "      <td>I am very upset about my recent asda order. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>Mo Plumb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB</td>\n",
       "      <td>2017-01-04 14:39:44.000</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>Disappointingly poor service from Asda.</td>\n",
       "      <td>Today I received delivery of my Asda shopping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11007</th>\n",
       "      <td>Matt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2017-01-03 16:07:17.837</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Home delivery late. Out of date food!!!</td>\n",
       "      <td>To be honest I don't think Asda care! Don't do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11008</th>\n",
       "      <td>Jim Mccrory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB</td>\n",
       "      <td>2017-01-03 14:23:14.000</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>shocking.</td>\n",
       "      <td>I am currently in asda robroyston and can't be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11009</th>\n",
       "      <td>Kat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>2017-01-02 14:35:23.029</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Overcharged</td>\n",
       "      <td>I ordered some shirts and a jumper to be deliv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               User  Rating Location                    Date ExperienceDate   \n",
       "11005  Julie Driver     NaN       GB 2017-01-05 18:59:56.000     2017-01-05  \\\n",
       "11006      Mo Plumb     NaN       GB 2017-01-04 14:39:44.000     2017-01-04   \n",
       "11007          Matt     1.0       GB 2017-01-03 16:07:17.837     2017-01-03   \n",
       "11008   Jim Mccrory     NaN       GB 2017-01-03 14:23:14.000     2017-01-03   \n",
       "11009           Kat     2.0       GB 2017-01-02 14:35:23.029     2017-01-02   \n",
       "\n",
       "                                 ReviewHeading   \n",
       "11005                           waste of money  \\\n",
       "11006  Disappointingly poor service from Asda.   \n",
       "11007  Home delivery late. Out of date food!!!   \n",
       "11008                                shocking.   \n",
       "11009                              Overcharged   \n",
       "\n",
       "                                           ReviewContent  \n",
       "11005  I am very upset about my recent asda order. Th...  \n",
       "11006  Today I received delivery of my Asda shopping ...  \n",
       "11007  To be honest I don't think Asda care! Don't do...  \n",
       "11008  I am currently in asda robroyston and can't be...  \n",
       "11009  I ordered some shirts and a jumper to be deliv...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the earlier dates\n",
    "filtered_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d38321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d431a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15abbb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d005574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d617ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b1fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369dd3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fdc498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07e3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b809346c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5438f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1901f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e7c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd8185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654a336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cacd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc08b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15058ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f828b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0771848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4bec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f51713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694de9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af727ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3c945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff31b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba241407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800859f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25c1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e255ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4479ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc6ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb46800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c507df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c0eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92a780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c05acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518a4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c19d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52db998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070abad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220488a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274c1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce77edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce64484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4384980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b657c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418a28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce233d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee07ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7be7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36234fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c0354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65503627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fdcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227fe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56cac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f1664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eb8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb00dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83486e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366a10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eae463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e992f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be5807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a5781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3dac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eee87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce9a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38364b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d9f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963083ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293cb617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe781bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b88a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444035d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe3656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb051dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90980d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18cb326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf285d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70555ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710be70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab5597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375ca78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02bea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acc1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49f7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4658cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62e5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cc09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a15467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3f592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacc23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528e095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f085f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3e120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
